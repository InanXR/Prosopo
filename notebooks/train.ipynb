{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosopo Training Notebook\n",
    "\n",
    "**Streamlined execution for face embedding training.**\n",
    "\n",
    "Prerequisites:\n",
    "- `aligned_casia.zip` in Google Drive (`/MyDrive/prosopo/`)\n",
    "- T4 GPU runtime enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Mount & Setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q albumentations tqdm\n",
    "\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/prosopo/checkpoints', exist_ok=True)\n",
    "print('‚úÖ Environment Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Restore the Asset (Zero Alignment Time)\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "zip_path = '/content/drive/MyDrive/prosopo/aligned_casia.zip'\n",
    "extract_path = '/content/data/aligned_casia'\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    print(f\"üöÄ Detected Backup at {zip_path}\")\n",
    "    print(\"üìÇ Extracting aligned faces... (~2-3 mins)\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/data/')\n",
    "        \n",
    "    print(\"‚úÖ Extraction Complete.\")\n",
    "else:\n",
    "    print(\"‚úÖ Data already extracted.\")\n",
    "\n",
    "# Verify count\n",
    "num_images = sum([len(files) for r, d, files in os.walk(extract_path)])\n",
    "print(f\"üì∏ Total Training Images: {num_images:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Clone The Brain\n",
    "import sys\n",
    "\n",
    "# Remove old repo if exists\n",
    "!rm -rf /content/prosopo\n",
    "\n",
    "# Clone fresh\n",
    "!git clone https://github.com/InanXR/Prosopo.git /content/prosopo\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, '/content/prosopo')\n",
    "\n",
    "# Verify imports\n",
    "try:\n",
    "    from prosopo.models import Prosopo\n",
    "    from prosopo.data import CASIAWebFaceDataset\n",
    "    from prosopo.training import Config\n",
    "    print(\"‚úÖ Codebase Integrity Verified. Imports working.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: The Training Loop\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from prosopo.models import Prosopo\n",
    "from prosopo.data import CASIAWebFaceDataset\n",
    "from prosopo.training import Config\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg = Config()\n",
    "cfg.data_root = '/content/data/aligned_casia'\n",
    "cfg.checkpoint_dir = '/content/drive/MyDrive/prosopo/checkpoints'\n",
    "\n",
    "# Augmentations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "print(\"üìÇ Loading Dataset...\")\n",
    "dataset = CASIAWebFaceDataset(cfg.data_root, transform=train_transform)\n",
    "train_loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=cfg.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=cfg.num_workers, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "NUM_CLASSES = dataset.num_classes\n",
    "print(f\"üéØ Classes: {NUM_CLASSES} | Samples: {len(dataset):,} | Device: {DEVICE}\")\n",
    "\n",
    "# Model\n",
    "model = Prosopo(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    embedding_dim=cfg.embedding_dim,\n",
    "    arcface_scale=cfg.arcface_scale,\n",
    "    arcface_margin=cfg.arcface_margin,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=cfg.lr, \n",
    "    momentum=cfg.momentum, \n",
    "    weight_decay=cfg.weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, \n",
    "    milestones=cfg.lr_milestones, \n",
    "    gamma=cfg.lr_gamma\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# --- RESUME CHECK ---\n",
    "start_epoch = 0\n",
    "resume_path = f\"{cfg.checkpoint_dir}/latest.pth\"\n",
    "\n",
    "if os.path.exists(resume_path):\n",
    "    print(\"üîÑ Resuming from checkpoint...\")\n",
    "    checkpoint = torch.load(resume_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"   Resuming from epoch {start_epoch}\")\n",
    "\n",
    "# --- TRAINING LOOP ---\n",
    "print(\"\\nüî• TRAINING STARTED\")\n",
    "print(f\"   Epochs: {start_epoch} ‚Üí {cfg.epochs}\")\n",
    "print(f\"   Batch Size: {cfg.batch_size}\")\n",
    "print(f\"   Learning Rate: {cfg.lr}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(start_epoch, cfg.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.epochs}\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward (Returns ArcFace Logits)\n",
    "        outputs = model(images, labels)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "    scheduler.step()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"üìä Epoch {epoch+1} complete. Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save Checkpoint\n",
    "    save_path = f\"{cfg.checkpoint_dir}/epoch_{epoch+1}.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, save_path)\n",
    "    \n",
    "    # Save 'latest' for easy resume\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, resume_path)\n",
    "    \n",
    "    print(f\"üíæ Checkpoint saved: {save_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ TRAINING COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Export Final Model\n",
    "import torch\n",
    "\n",
    "final_path = '/content/drive/MyDrive/prosopo/prosopo_final.pth'\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(f'‚úÖ Final model saved to: {final_path}')\n",
    "\n",
    "# Download locally\n",
    "from google.colab import files\n",
    "files.download(final_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
