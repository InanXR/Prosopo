{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUzHlH8rZIZw"
      },
      "source": [
        "# Prosopo Training Notebook\n",
        "\n",
        "Train a face embedding model from scratch using ArcFace loss.\n",
        "\n",
        "**Target:** 99%+ accuracy on LFW benchmark\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Overview\n",
        "1. Mount Drive (checkpoint survival)\n",
        "2. Download CASIA-WebFace from Kaggle (.rec format)\n",
        "3. Unpack RecordIO â†’ raw images\n",
        "4. Align faces with MTCNN â†’ 112Ã—112\n",
        "5. Train ResNet-50 + ArcFace\n",
        "6. Evaluate on LFW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDpS0DDfZIZx"
      },
      "source": [
        "## 1. Setup & Mount Drive\n",
        "\n",
        "âš ï¸ **CRITICAL:** Mount Drive FIRST to ensure checkpoints survive session disconnects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dQqyLCFnZIZx",
        "outputId": "65086216-4999-4dd5-974c-371f352a614b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Drive mounted\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/prosopo/checkpoints', exist_ok=True)\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "print('âœ… Drive mounted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3kGyUevZIZy",
        "outputId": "b1fe3c94-a6e9-4015-db9b-dc43ad5073b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/18.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/18.0 MB\u001b[0m \u001b[31m205.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/18.0 MB\u001b[0m \u001b[31m163.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m17.2/18.0 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m17.9/18.0 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires numpy<2.0.0,>=1.24.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.21.0 requires graphviz<1.0.0,>=0.20.2, but you have graphviz 0.8.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# CRITICAL: Force numpy<2.0 because mxnet and facenet-pytorch are broken on numpy 2.x\n",
        "!pip install -q \"numpy<2.0.0\"\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q albumentations facenet-pytorch scikit-image\n",
        "!pip install -q tqdm scikit-learn opencv-python\n",
        "!pip install -q mxnet  # For RecordIO unpacking\n",
        "!pip install -q kaggle\n",
        "\n",
        "print('âœ… Dependencies installed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CPc0_lwaZIZy",
        "outputId": "cf5b27a1-ca33-4323-c922-8853253ee0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/prosopo'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 47 (delta 9), reused 45 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (47/47), 28.99 KiB | 5.80 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "âœ… /content/prosopo/prosopo/__init__.py\n",
            "âœ… /content/prosopo/prosopo/models/arcface.py\n",
            "âœ… /content/prosopo/prosopo/training/trainer.py\n",
            "âœ… /content/prosopo/prosopo/data/dataset.py\n",
            "âœ… /content/prosopo/scripts/preprocess.py\n",
            "\n",
            "âœ… Prosopo repo verified!\n"
          ]
        }
      ],
      "source": [
        "# Clone Prosopo repo and verify structure\n",
        "!git clone https://github.com/InanXR/Prosopo.git /content/prosopo\n",
        "\n",
        "# Verify the package exists\n",
        "import os\n",
        "expected_files = [\n",
        "    '/content/prosopo/prosopo/__init__.py',\n",
        "    '/content/prosopo/prosopo/models/arcface.py',\n",
        "    '/content/prosopo/prosopo/training/trainer.py',\n",
        "    '/content/prosopo/prosopo/data/dataset.py',\n",
        "    '/content/prosopo/scripts/preprocess.py',\n",
        "]\n",
        "\n",
        "all_ok = True\n",
        "for f in expected_files:\n",
        "    if os.path.exists(f):\n",
        "        print(f'âœ… {f}')\n",
        "    else:\n",
        "        print(f'âŒ MISSING: {f}')\n",
        "        all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print('\\nâœ… Prosopo repo verified!')\n",
        "else:\n",
        "    print('\\nâŒ Some files missing - check GitHub repo!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDSA6j7HZIZy"
      },
      "source": [
        "## 2. Setup Kaggle API\n",
        "\n",
        "Using Global Access Token (KGAT) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gHcIR8zyZIZy",
        "outputId": "a0ef72b4-d053-42b6-c51d-fb9e274fe9fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Kaggle credentials configured\n",
            "ref                                                           title                                                      size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  --------------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "jessicali9530/animal-crossing-new-horizons-nookplaza-dataset  Animal Crossing New Horizons Catalog                     590770  2021-06-08 15:05:09.513000          83596      56002  0.88235295       \n"
          ]
        }
      ],
      "source": [
        "# Configure Kaggle credentials\n",
        "import os\n",
        "import json\n",
        "\n",
        "# 1. Define credentials\n",
        "kaggle_username = 'inanxr'\n",
        "kaggle_token = 'KGAT_1200fe88c38a44a77c8879998f9413ac'\n",
        "\n",
        "# 2. Manually create kaggle.json to avoid client errors\n",
        "kaggle_dir = os.path.expanduser('~/.kaggle')\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(kaggle_dir, 'kaggle.json'), 'w') as f:\n",
        "    # Note: KGAT acts as the 'key'\n",
        "    json.dump({'username': kaggle_username, 'key': kaggle_token}, f)\n",
        "\n",
        "# 3. Set permissions\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('âœ… Kaggle credentials configured')\n",
        "\n",
        "# 4. Verify it works\n",
        "!kaggle datasets list --sort-by votes 2>&1 | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jx_6W7gZIZz"
      },
      "source": [
        "## 3. Download CASIA-WebFace from Kaggle\n",
        "\n",
        "Dataset: `debarghamitraroy/casia-webface` (~2.73 GB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2rgUeUbtZIZz",
        "outputId": "69bf6bbe-72b3-4bd3-fb9d-aae5c4b38d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/debarghamitraroy/casia-webface\n",
            "License(s): DbCL-1.0\n",
            "Downloading casia-webface.zip to /content/data\n",
            " 99% 2.67G/2.70G [00:17<00:00, 256MB/s]\n",
            "100% 2.70G/2.70G [00:17<00:00, 163MB/s]\n",
            "\n",
            "âœ… Download complete. Checking contents...\n",
            "total 2.7G\n",
            "-rw-r--r-- 1 root root 2.7G Dec 22 13:33 casia-webface.zip\n"
          ]
        }
      ],
      "source": [
        "# Download CASIA-WebFace dataset\n",
        "!kaggle datasets download -d debarghamitraroy/casia-webface -p /content/data/\n",
        "\n",
        "print('\\nâœ… Download complete. Checking contents...')\n",
        "!ls -lh /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M1f-X-z_ZIZz",
        "outputId": "b4cd8c4a-a63d-423e-9ecd-3c5ad37a4375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contents after unzip:\n",
            "/content/data/raw_rec/casia-webface/train.idx\n",
            "/content/data/raw_rec/casia-webface/train.rec\n",
            "\n",
            "Found .rec files: ['/content/data/raw_rec/casia-webface/train.rec']\n"
          ]
        }
      ],
      "source": [
        "# Unzip and verify structure\n",
        "!unzip -q /content/data/casia-webface.zip -d /content/data/raw_rec\n",
        "\n",
        "print('\\nContents after unzip:')\n",
        "!find /content/data/raw_rec -name \"*.rec\" -o -name \"*.idx\" | head -20\n",
        "\n",
        "# Find the .rec file path\n",
        "import glob\n",
        "rec_files = glob.glob('/content/data/raw_rec/**/*.rec', recursive=True)\n",
        "print(f'\\nFound .rec files: {rec_files}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_23-D7EZIZz"
      },
      "source": [
        "## 4. Unpack RecordIO to Raw Images\n",
        "\n",
        "The dataset comes in MXNet RecordIO format. We unpack it to folders.\n",
        "\n",
        "â±ï¸ **Time:** ~30 minutes for 490K images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8S3jaeLFZIZz",
        "outputId": "d5a4565e-ea44-4a4e-b0f2-81dc4b6497cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3375138610.py:9: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, 'bool'):\n",
            "/tmp/ipython-input-3375138610.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, 'object'):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- ğŸ› ï¸ HOTFIX: Patch NumPy for MXNet Compatibility ğŸ› ï¸ ---\n",
        "# MXNet is an older library and looks for 'np.bool' and 'np.object', which\n",
        "# were removed in modern NumPy. We manually restore them here to prevent crashes.\n",
        "if not hasattr(np, 'bool'):\n",
        "    np.bool = bool\n",
        "if not hasattr(np, 'object'):\n",
        "    np.object = object\n",
        "if not hasattr(np, 'float'):\n",
        "    np.float = float\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "import mxnet as mx\n",
        "from mxnet import recordio\n",
        "\n",
        "def unpack_rec_file(rec_path, output_dir):\n",
        "    \"\"\"\n",
        "    Unpack MXNet RecordIO file to image folders using OpenCV for decoding.\n",
        "    \"\"\"\n",
        "    print(f\"Unpacking {rec_path}...\")\n",
        "\n",
        "    idx_path = rec_path.replace('.rec', '.idx')\n",
        "    if not os.path.exists(rec_path):\n",
        "        raise FileNotFoundError(f\"{rec_path} not found!\")\n",
        "    if not os.path.exists(idx_path):\n",
        "        raise FileNotFoundError(f\"{idx_path} not found! (Required alongside .rec)\")\n",
        "\n",
        "    # Open RecordIO\n",
        "    imgrec = recordio.MXIndexedRecordIO(idx_path, rec_path, 'r')\n",
        "\n",
        "    # Read header to get total count\n",
        "    s = imgrec.read_idx(0)\n",
        "    header, _ = recordio.unpack(s)\n",
        "\n",
        "    if isinstance(header.label, float):\n",
        "        num_images = int(header.label)\n",
        "    else:\n",
        "        num_images = int(header.label[0])\n",
        "\n",
        "    print(f\"Total images: {num_images:,}\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    # Iterate and unpack\n",
        "    for idx in tqdm(range(1, num_images + 1), desc=\"Unpacking\", mininterval=1.0):\n",
        "        try:\n",
        "            s = imgrec.read_idx(idx)\n",
        "            header, img_data = recordio.unpack(s)\n",
        "\n",
        "            # --- OPTIMIZATION: Use OpenCV directly instead of MXNet ---\n",
        "            # 1. Convert bytes to numpy array\n",
        "            nparr = np.frombuffer(img_data, dtype=np.uint8)\n",
        "            # 2. Decode directly to BGR (ready for imwrite)\n",
        "            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "            if img is None:\n",
        "                raise ValueError(\"Image decode failed\")\n",
        "\n",
        "            # Handle label format\n",
        "            if isinstance(header.label, float):\n",
        "                label = int(header.label)\n",
        "            else:\n",
        "                label = int(header.label[0])\n",
        "\n",
        "            # Create folder structure\n",
        "            folder_name = f\"{label:07d}\"\n",
        "            save_dir = os.path.join(output_dir, folder_name)\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            # Save image\n",
        "            filename = f\"{idx}.jpg\"\n",
        "            cv2.imwrite(os.path.join(save_dir, filename), img)\n",
        "            success_count += 1\n",
        "\n",
        "        except Exception:\n",
        "            error_count += 1\n",
        "            continue\n",
        "\n",
        "    print(f\"\\nâœ… Unpacked {success_count:,} images ({error_count} errors)\")\n",
        "    print(f\"   Output: {output_dir}\")\n",
        "    print(f\"   Identities: {len(os.listdir(output_dir))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "acVH6s80ZIZz",
        "outputId": "3dc7b990-305f-45c4-8b0f-3e6d6a0e8492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: /content/data/raw_rec/casia-webface/train.rec\n",
            "Unpacking /content/data/raw_rec/casia-webface/train.rec...\n",
            "Total images: 490,624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unpacking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 490624/490624 [03:03<00:00, 2667.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Unpacked 490,623 images (1 errors)\n",
            "   Output: /content/data/raw_casia\n",
            "   Identities: 10572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Find and unpack the .rec file\n",
        "import glob\n",
        "\n",
        "rec_files = glob.glob('/content/data/raw_rec/**/*.rec', recursive=True)\n",
        "\n",
        "if not rec_files:\n",
        "    print(\"âŒ No .rec file found! Checking directory structure...\")\n",
        "    !find /content/data -type f | head -30\n",
        "else:\n",
        "    rec_path = rec_files[0]\n",
        "    print(f\"Using: {rec_path}\")\n",
        "    unpack_rec_file(rec_path, '/content/data/raw_casia')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zPUBgRsZIZz"
      },
      "source": [
        "## 5. Align Faces with MTCNN\n",
        "\n",
        "Detect faces and warp to canonical 112Ã—112 pose.\n",
        "\n",
        "â±ï¸ **Time:** ~2-4 hours for 490K images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyx5lNsZZIZ0",
        "outputId": "27425a7e-ca9a-490f-ecbd-d3655954e2e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Acceleration: cuda:0\n",
            "ğŸ“‚ Found 490,623 images. Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Aligning:   3%|â–         | 264/7666 [05:02<2:28:52,  1.21s/batch]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "INPUT_ROOT = '/content/data/raw_casia'\n",
        "OUTPUT_ROOT = '/content/data/aligned_casia'\n",
        "BATCH_SIZE = 64     # Reduced slightly for safety with resizing\n",
        "NUM_WORKERS = 2\n",
        "TARGET_SIZE = 640   # Standardize inputs to this size for batching\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸš€ Acceleration: {device}\")\n",
        "\n",
        "# Initialize MTCNN\n",
        "mtcnn = MTCNN(\n",
        "    image_size=112,\n",
        "    margin=0,\n",
        "    min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7],\n",
        "    factor=0.709,\n",
        "    post_process=True,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Helper: Resize image to square with padding (preserves aspect ratio)\n",
        "def resize_pad(img, target_size):\n",
        "    old_size = img.size  # (width, height)\n",
        "    ratio = float(target_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "    img = img.resize(new_size, Image.BILINEAR)\n",
        "\n",
        "    # Create new square image and paste resized img in center\n",
        "    new_im = Image.new(\"RGB\", (target_size, target_size))\n",
        "    new_im.paste(img, ((target_size-new_size[0])//2,\n",
        "                       (target_size-new_size[1])//2))\n",
        "    return new_im\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_paths[idx]\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            # Critical Fix: Standardize size so they can be batched!\n",
        "            img = resize_pad(img, TARGET_SIZE)\n",
        "        except Exception:\n",
        "            return None, None\n",
        "        return img, path\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if len(batch) == 0:\n",
        "        return [], []\n",
        "    return zip(*batch)\n",
        "\n",
        "# Collect Files\n",
        "files = glob.glob(f\"{INPUT_ROOT}/**/*.jpg\", recursive=True)\n",
        "print(f\"ğŸ“‚ Found {len(files):,} images. Processing...\")\n",
        "\n",
        "# Run Batch Alignment\n",
        "dataset = FaceDataset(files)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "aligned_count = 0\n",
        "errors = 0\n",
        "\n",
        "for imgs, paths in tqdm(loader, desc=\"Aligning\", unit=\"batch\"):\n",
        "    if not imgs: continue\n",
        "\n",
        "    save_paths = []\n",
        "    for p in paths:\n",
        "        rel_path = os.path.relpath(p, INPUT_ROOT)\n",
        "        out_path = os.path.join(OUTPUT_ROOT, rel_path)\n",
        "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "        save_paths.append(out_path)\n",
        "\n",
        "    try:\n",
        "        # Convert tuple to list for MTCNN\n",
        "        mtcnn(list(imgs), save_path=save_paths)\n",
        "        aligned_count += len(imgs)\n",
        "    except Exception as e:\n",
        "        errors += 1\n",
        "        continue\n",
        "\n",
        "print(f\"\\nâœ¨ Complete! Processed {aligned_count:,} images.\")\n",
        "\n",
        "# Generate class_indices.json\n",
        "classes = [d for d in os.listdir(OUTPUT_ROOT) if os.path.isdir(os.path.join(OUTPUT_ROOT, d))]\n",
        "classes.sort()\n",
        "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "\n",
        "json_path = os.path.join(OUTPUT_ROOT, 'class_indices.json')\n",
        "with open(json_path, 'w') as f:\n",
        "    json.dump(class_to_idx, f, indent=4)\n",
        "print(f\"âœ… Saved class indices. Total Classes: {len(classes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zao4walcZIZ0"
      },
      "outputs": [],
      "source": [
        "# Verify alignment results\n",
        "import os\n",
        "\n",
        "aligned_dir = '/content/data/aligned_casia'\n",
        "\n",
        "if os.path.exists(aligned_dir):\n",
        "    num_identities = len([d for d in os.listdir(aligned_dir)\n",
        "                          if os.path.isdir(os.path.join(aligned_dir, d))])\n",
        "\n",
        "    total_images = sum(len(files) for _, _, files in os.walk(aligned_dir))\n",
        "\n",
        "    print(f\"âœ… Alignment complete!\")\n",
        "    print(f\"   Identities: {num_identities:,}\")\n",
        "    print(f\"   Total aligned images: {total_images:,}\")\n",
        "\n",
        "    # Check for class_indices.json\n",
        "    if os.path.exists(f\"{aligned_dir}/class_indices.json\"):\n",
        "        print(f\"   âœ… class_indices.json exists\")\n",
        "    else:\n",
        "        print(f\"   âš ï¸ class_indices.json not found\")\n",
        "else:\n",
        "    print(\"âŒ Aligned directory not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "source_dir = '/content/data/aligned_casia'\n",
        "backup_path = '/content/drive/MyDrive/prosopo/aligned_casia.zip'\n",
        "\n",
        "print(f\"ğŸ“¦ Zipping dataset... this may take a few minutes...\")\n",
        "shutil.make_archive(backup_path.replace('.zip', ''), 'zip', source_dir)\n",
        "\n",
        "print(f\"âœ… Backup saved to: {backup_path}\")\n",
        "print(\"   (If the session crashes, you can just unzip this file instead of realigning!)\")"
      ],
      "metadata": {
        "id": "zuUvGGRgfcVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz5oYQDWZIZ0"
      },
      "source": [
        "## 6. Download LFW for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUntTA_jZIZ0"
      },
      "outputs": [],
      "source": [
        "# Download LFW\n",
        "!wget -q http://vis-www.cs.umass.edu/lfw/lfw.tgz -O /content/data/lfw.tgz\n",
        "!tar -xzf /content/data/lfw.tgz -C /content/data/\n",
        "!wget -q http://vis-www.cs.umass.edu/lfw/pairs.txt -O /content/data/pairs.txt\n",
        "\n",
        "print('âœ… LFW downloaded')\n",
        "!ls /content/data/lfw | head -5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5BzXorDZIZ0"
      },
      "source": [
        "## 7. Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnLTzG_dZIZ0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/prosopo')\n",
        "\n",
        "# Test import\n",
        "try:\n",
        "    from prosopo.training import TrainingConfig, Trainer\n",
        "    from prosopo.models import Prosopo\n",
        "    print('âœ… Prosopo imports successful')\n",
        "except ImportError as e:\n",
        "    print(f'âŒ Import failed: {e}')\n",
        "    print('\\nCheck that all files were pushed to GitHub!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvtMJZpbZIZ0"
      },
      "outputs": [],
      "source": [
        "from prosopo.training import TrainingConfig\n",
        "\n",
        "config = TrainingConfig(\n",
        "    # Data paths\n",
        "    data_root='/content/data/aligned_casia',\n",
        "    class_indices_path='/content/data/aligned_casia/class_indices.json',\n",
        "    lfw_root='/content/data/lfw',\n",
        "    lfw_pairs_path='/content/data/pairs.txt',\n",
        "\n",
        "    # Model\n",
        "    backbone='resnet50',\n",
        "    embedding_dim=512,\n",
        "    pretrained=True,\n",
        "\n",
        "    # ArcFace\n",
        "    arcface_scale=64.0,\n",
        "    arcface_margin=0.5,\n",
        "\n",
        "    # Training\n",
        "    batch_size=128,\n",
        "    accumulation_steps=2,\n",
        "    epochs=25,\n",
        "    lr=0.1,\n",
        "    num_workers=2,\n",
        "\n",
        "    # Checkpointing\n",
        "    checkpoint_dir='/content/drive/MyDrive/prosopo/checkpoints',\n",
        "    save_every=1,\n",
        "    val_epochs=[10, 15, 20, 25],\n",
        "\n",
        "    # Resume (set path if session crashed)\n",
        "    resume_from=None,  # e.g., '/content/drive/MyDrive/prosopo/checkpoints/epoch_10.pth'\n",
        ")\n",
        "\n",
        "print('âœ… Config ready')\n",
        "print(f'   Batch size: {config.batch_size} x {config.accumulation_steps} = {config.batch_size * config.accumulation_steps} effective')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDTz5dH1ZIZ0"
      },
      "source": [
        "## 8. Train Model\n",
        "\n",
        "â±ï¸ **Expected time:** ~8-12 hours on T4 GPU\n",
        "\n",
        "If session disconnects:\n",
        "1. Re-run cells 1-6 (they're fast - data is cached)\n",
        "2. Set `resume_from` to last checkpoint path\n",
        "3. Re-run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRz9DIvWZIZ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGRzdWguZIZ0"
      },
      "outputs": [],
      "source": [
        "from prosopo.training import Trainer\n",
        "\n",
        "trainer = Trainer(config)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W27mcE0ZIZ0"
      },
      "source": [
        "## 9. Final Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjHzlTSpZIZ0"
      },
      "outputs": [],
      "source": [
        "from prosopo.evaluation import evaluate_lfw\n",
        "\n",
        "accuracy, threshold = evaluate_lfw(\n",
        "    trainer.model,\n",
        "    config.lfw_root,\n",
        "    config.lfw_pairs_path,\n",
        ")\n",
        "\n",
        "print(f'\\nğŸ¯ LFW Accuracy: {accuracy:.2%}')\n",
        "print(f'   Optimal threshold: {threshold:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kW_lgjFZIZ0"
      },
      "source": [
        "## 10. Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65EVjxM3ZIZ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "final_path = '/content/drive/MyDrive/prosopo/prosopo_final.pth'\n",
        "torch.save(trainer.model.state_dict(), final_path)\n",
        "print(f'âœ… Model saved to: {final_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5szHx5ZdZIZ1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(final_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
