{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosopo Training Notebook\n",
    "\n",
    "Train a face embedding model from scratch using ArcFace loss.\n",
    "\n",
    "**Target:** 99%+ accuracy on LFW benchmark\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Overview\n",
    "1. Mount Drive (checkpoint survival)\n",
    "2. Download CASIA-WebFace from Kaggle (.rec format)\n",
    "3. Unpack RecordIO ‚Üí raw images\n",
    "4. Align faces with MTCNN ‚Üí 112√ó112\n",
    "5. Train ResNet-50 + ArcFace\n",
    "6. Evaluate on LFW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Mount Drive\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL:** Mount Drive FIRST to ensure checkpoints survive session disconnects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/prosopo/checkpoints', exist_ok=True)\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "print('‚úÖ Drive mounted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q albumentations facenet-pytorch scikit-image\n",
    "!pip install -q tqdm scikit-learn opencv-python\n",
    "!pip install -q mxnet  # For RecordIO unpacking\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Clone Prosopo repo\n",
    "!git clone https://github.com/InanXR/Prosopo.git /content/prosopo\n",
    "\n",
    "print('‚úÖ Dependencies installed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download CASIA-WebFace from Kaggle\n",
    "\n",
    "Dataset: `debarghamitraroy/casia-webface` (~2.73 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle API credentials\n",
    "import os\n",
    "\n",
    "# Set your Kaggle API token\n",
    "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_1200fe88c38a44a77c8879998f9413ac'\n",
    "\n",
    "# Alternative: Create kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "kaggle_json = '{\"username\":\"YOUR_KAGGLE_USERNAME\",\"key\":\"YOUR_KAGGLE_KEY\"}'\n",
    "# Uncomment and fill in if token method doesn't work:\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "#     f.write(kaggle_json)\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print('‚úÖ Kaggle credentials configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CASIA-WebFace dataset\n",
    "!kaggle datasets download -d debarghamitraroy/casia-webface -p /content/data/\n",
    "!unzip -q /content/data/casia-webface.zip -d /content/data/raw_rec\n",
    "\n",
    "# Check what we got\n",
    "!ls -lh /content/data/raw_rec/\n",
    "print('‚úÖ Dataset downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unpack RecordIO to Raw Images\n",
    "\n",
    "The dataset comes in MXNet RecordIO format. We unpack it to folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import recordio\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def unpack_rec_file(rec_path, output_dir):\n",
    "    \"\"\"\n",
    "    Unpack MXNet RecordIO file to image folders.\n",
    "    \n",
    "    Creates structure:\n",
    "        output_dir/\n",
    "            0000001/\n",
    "                1.jpg\n",
    "                2.jpg\n",
    "            0000002/\n",
    "                ...\n",
    "    \"\"\"\n",
    "    print(f\"Unpacking {rec_path} to {output_dir}...\")\n",
    "    \n",
    "    idx_path = rec_path.replace('.rec', '.idx')\n",
    "    if not os.path.exists(rec_path):\n",
    "        print(f\"‚ùå Error: {rec_path} not found!\")\n",
    "        # Try to find .rec file\n",
    "        import glob\n",
    "        rec_files = glob.glob('/content/data/raw_rec/**/*.rec', recursive=True)\n",
    "        print(f\"Found .rec files: {rec_files}\")\n",
    "        return\n",
    "    \n",
    "    # Open RecordIO\n",
    "    imgrec = recordio.MXIndexedRecordIO(idx_path, rec_path, 'r')\n",
    "    \n",
    "    # Read header to get total count\n",
    "    s = imgrec.read_idx(0)\n",
    "    header, _ = recordio.unpack(s)\n",
    "    \n",
    "    # header.label[0] contains the number of images\n",
    "    if isinstance(header.label, float):\n",
    "        num_images = int(header.label)\n",
    "    else:\n",
    "        num_images = int(header.label[0])\n",
    "    \n",
    "    print(f\"Total images to unpack: {num_images}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Unpack each image\n",
    "    for idx in tqdm(range(1, num_images + 1), desc=\"Unpacking\"):\n",
    "        try:\n",
    "            s = imgrec.read_idx(idx)\n",
    "            header, img_data = recordio.unpack(s)\n",
    "            \n",
    "            # Decode image\n",
    "            img = mx.image.imdecode(img_data).asnumpy()\n",
    "            \n",
    "            # Convert RGB (MXNet) to BGR (OpenCV)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Get label (identity)\n",
    "            if isinstance(header.label, float):\n",
    "                label = int(header.label)\n",
    "            else:\n",
    "                label = int(header.label[0])\n",
    "            \n",
    "            # Create identity folder\n",
    "            folder_name = f\"{label:07d}\"\n",
    "            save_dir = os.path.join(output_dir, folder_name)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            \n",
    "            # Save image\n",
    "            filename = f\"{idx}.jpg\"\n",
    "            cv2.imwrite(os.path.join(save_dir, filename), img)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if idx % 10000 == 0:\n",
    "                print(f\"Warning at {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Unpacked to {output_dir}\")\n",
    "    print(f\"   Identities: {len(os.listdir(output_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and unpack the .rec file\n",
    "import glob\n",
    "\n",
    "rec_files = glob.glob('/content/data/raw_rec/**/*.rec', recursive=True)\n",
    "print(f\"Found .rec files: {rec_files}\")\n",
    "\n",
    "if rec_files:\n",
    "    rec_path = rec_files[0]\n",
    "    unpack_rec_file(rec_path, '/content/data/raw_casia')\n",
    "else:\n",
    "    print(\"‚ùå No .rec file found! Check the download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Align Faces with MTCNN\n",
    "\n",
    "Detect faces and warp to canonical 112√ó112 pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run alignment (this takes ~2-4 hours for full dataset)\n",
    "import sys\n",
    "sys.path.insert(0, '/content/prosopo')\n",
    "\n",
    "!python /content/prosopo/scripts/preprocess.py \\\n",
    "    --input /content/data/raw_casia \\\n",
    "    --output /content/data/aligned_casia \\\n",
    "    --skip-existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify alignment results\n",
    "import os\n",
    "\n",
    "aligned_dir = '/content/data/aligned_casia'\n",
    "num_identities = len([d for d in os.listdir(aligned_dir) if os.path.isdir(os.path.join(aligned_dir, d))])\n",
    "\n",
    "total_images = sum(\n",
    "    len(files) for _, _, files in os.walk(aligned_dir)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Alignment complete!\")\n",
    "print(f\"   Identities: {num_identities}\")\n",
    "print(f\"   Total aligned images: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download LFW for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download LFW\n",
    "!wget -q http://vis-www.cs.umass.edu/lfw/lfw.tgz -O /content/data/lfw.tgz\n",
    "!tar -xzf /content/data/lfw.tgz -C /content/data/\n",
    "\n",
    "# Download pairs.txt\n",
    "!wget -q http://vis-www.cs.umass.edu/lfw/pairs.txt -O /content/data/pairs.txt\n",
    "\n",
    "print('‚úÖ LFW downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/prosopo')\n",
    "\n",
    "from prosopo.training import TrainingConfig, Trainer\n",
    "\n",
    "# Training configuration\n",
    "config = TrainingConfig(\n",
    "    # Data paths\n",
    "    data_root='/content/data/aligned_casia',\n",
    "    class_indices_path='/content/data/aligned_casia/class_indices.json',\n",
    "    lfw_root='/content/data/lfw',\n",
    "    lfw_pairs_path='/content/data/pairs.txt',\n",
    "    \n",
    "    # Model\n",
    "    backbone='resnet50',\n",
    "    embedding_dim=512,\n",
    "    pretrained=True,\n",
    "    \n",
    "    # ArcFace\n",
    "    arcface_scale=64.0,\n",
    "    arcface_margin=0.5,\n",
    "    \n",
    "    # Training\n",
    "    batch_size=128,\n",
    "    accumulation_steps=2,\n",
    "    epochs=25,\n",
    "    lr=0.1,\n",
    "    num_workers=2,\n",
    "    \n",
    "    # Checkpointing (to Drive!)\n",
    "    checkpoint_dir='/content/drive/MyDrive/prosopo/checkpoints',\n",
    "    save_every=1,\n",
    "    \n",
    "    # Validation epochs\n",
    "    val_epochs=[10, 15, 20, 25],\n",
    "    \n",
    "    # Resume from checkpoint (set path if resuming after disconnect)\n",
    "    resume_from=None,\n",
    ")\n",
    "\n",
    "print('‚úÖ Config ready')\n",
    "print(f'   Effective batch size: {config.batch_size * config.accumulation_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model\n",
    "\n",
    "‚è±Ô∏è **Expected time:** ~8-12 hours on T4 GPU\n",
    "\n",
    "If session disconnects, change `resume_from` to the last checkpoint path and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer and start training\n",
    "trainer = Trainer(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prosopo.evaluation import evaluate_lfw\n",
    "\n",
    "accuracy, threshold = evaluate_lfw(\n",
    "    trainer.model,\n",
    "    config.lfw_root,\n",
    "    config.lfw_pairs_path,\n",
    ")\n",
    "\n",
    "print(f'\\nüéØ LFW Accuracy: {accuracy:.2%}')\n",
    "print(f'   Optimal threshold: {threshold:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model to Drive\n",
    "import torch\n",
    "\n",
    "final_path = '/content/drive/MyDrive/prosopo/prosopo_final.pth'\n",
    "torch.save(trainer.model.state_dict(), final_path)\n",
    "\n",
    "print(f'‚úÖ Model saved to: {final_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download to local machine\n",
    "from google.colab import files\n",
    "files.download(final_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
