{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosopo Training (Self-Contained)\n",
    "\n",
    "All code inline. No external imports. Just run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install -q torch torchvision tqdm\n",
    "\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/prosopo/checkpoints', exist_ok=True)\n",
    "print('âœ… Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Extract Data\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = '/content/drive/MyDrive/prosopo/aligned_casia.zip'\n",
    "extract_path = '/content/data/aligned_casia'\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    print('ðŸ“‚ Extracting...')\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall('/content/data/')\n",
    "    print('âœ… Done')\n",
    "else:\n",
    "    print('âœ… Already extracted')\n",
    "\n",
    "print(f'ðŸ“¸ Images: {sum(len(f) for _,_,f in os.walk(extract_path)):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Everything Inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === DATASET ===\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = glob.glob(os.path.join(root, '*', '*.jpg'))\n",
    "        self.classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.images[idx]\n",
    "        label = self.class_to_idx[os.path.basename(os.path.dirname(path))]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# === ARCFACE HEAD ===\n",
    "class ArcFace(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, s=64.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - cosine.pow(2).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = F.one_hot(label, self.weight.size(0)).float()\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        return output * self.s\n",
    "\n",
    "# === MODEL ===\n",
    "class Prosopo(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=512):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights='IMAGENET1K_V1')\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.fc = nn.Linear(2048, embed_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(embed_dim)\n",
    "        self.head = ArcFace(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, label=None):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn2(x)\n",
    "        if label is not None:\n",
    "            return self.head(x, label)\n",
    "        return F.normalize(x)\n",
    "\n",
    "print('âœ… Classes defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_ROOT = '/content/data/aligned_casia'\n",
    "CKPT_DIR = '/content/drive/MyDrive/prosopo/checkpoints'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 25\n",
    "LR = 0.1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "print('ðŸ“‚ Loading data...')\n",
    "dataset = FaceDataset(DATA_ROOT, transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "NUM_CLASSES = len(dataset.classes)\n",
    "print(f'ðŸŽ¯ Classes: {NUM_CLASSES} | Samples: {len(dataset):,} | Device: {DEVICE}')\n",
    "\n",
    "model = Prosopo(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [10, 18, 22], 0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Resume\n",
    "start_epoch = 0\n",
    "resume = f'{CKPT_DIR}/latest.pth'\n",
    "if os.path.exists(resume):\n",
    "    ckpt = torch.load(resume)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optim'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    print(f'ðŸ”„ Resuming from epoch {start_epoch}')\n",
    "\n",
    "print(f'\\nðŸ”¥ Training epochs {start_epoch} â†’ {EPOCHS}')\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs, labels)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save\n",
    "    torch.save({'epoch': epoch, 'model': model.state_dict(), 'optim': optimizer.state_dict()},\n",
    "               f'{CKPT_DIR}/epoch_{epoch+1}.pth')\n",
    "    torch.save({'epoch': epoch, 'model': model.state_dict(), 'optim': optimizer.state_dict()}, resume)\n",
    "    print(f'ðŸ’¾ Epoch {epoch+1} saved. Avg loss: {total_loss/len(loader):.4f}')\n",
    "\n",
    "print('\\nâœ… DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Export\n",
    "final = '/content/drive/MyDrive/prosopo/prosopo_final.pth'\n",
    "torch.save(model.state_dict(), final)\n",
    "print(f'âœ… Saved to {final}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {"gpuType": "T4", "provenance": []},
  "kernelspec": {"display_name": "Python 3", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
