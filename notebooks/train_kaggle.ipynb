{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prosopo Training (Kaggle)\n",
    "\n",
    "Resume training from Google Drive checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Extract Data from Kaggle Dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path depends on your dataset name (change if different)\n",
    "zip_path = '/kaggle/input/prosopo-data/aligned_casia.zip'\n",
    "ckpt_path = '/kaggle/input/prosopo-data/latest.pth'\n",
    "extract_path = '/kaggle/working/aligned_casia'\n",
    "output_dir = '/kaggle/working/checkpoints'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    print('ðŸ“‚ Extracting dataset...')\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall('/kaggle/working/')\n",
    "    print('âœ… Extracted')\n",
    "else:\n",
    "    print('âœ… Already extracted')\n",
    "\n",
    "print(f'ðŸ“¸ Images: {sum(len(f) for _,_,f in os.walk(extract_path)):,}')\n",
    "print(f'ðŸ“¦ Checkpoint: {os.path.exists(ckpt_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Model & Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.images = glob.glob(os.path.join(root, '*', '*.jpg'))\n",
    "        self.classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.images[idx]\n",
    "        label = self.class_to_idx[os.path.basename(os.path.dirname(path))]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "class ArcFace(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, s=64.0, m=0.5):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - cosine.pow(2).clamp(0, 1))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = F.one_hot(label, self.weight.size(0)).float()\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        return output * self.s\n",
    "\n",
    "class Prosopo(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=512):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights='IMAGENET1K_V1')\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.fc = nn.Linear(2048, embed_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(embed_dim)\n",
    "        self.head = ArcFace(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, label=None):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn2(x)\n",
    "        if label is not None:\n",
    "            return self.head(x, label)\n",
    "        return F.normalize(x)\n",
    "\n",
    "print('âœ… Classes defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Train\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_ROOT = '/kaggle/working/aligned_casia'\n",
    "CKPT_DIR = '/kaggle/working/checkpoints'\n",
    "RESUME_CKPT = '/kaggle/input/prosopo-data/latest.pth'  # From uploaded dataset\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 25\n",
    "LR = 0.1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "print('ðŸ“‚ Loading data...')\n",
    "dataset = FaceDataset(DATA_ROOT, transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "NUM_CLASSES = len(dataset.classes)\n",
    "print(f'ðŸŽ¯ Classes: {NUM_CLASSES} | Samples: {len(dataset):,} | Device: {DEVICE}')\n",
    "\n",
    "model = Prosopo(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [10, 18, 22], 0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Resume from uploaded checkpoint\n",
    "start_epoch = 0\n",
    "if os.path.exists(RESUME_CKPT):\n",
    "    print(f'ðŸ”„ Loading checkpoint from {RESUME_CKPT}')\n",
    "    ckpt = torch.load(RESUME_CKPT, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optim'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    # Advance scheduler to correct position\n",
    "    for _ in range(start_epoch):\n",
    "        scheduler.step()\n",
    "    print(f'âœ… Resuming from epoch {start_epoch}')\n",
    "\n",
    "print(f'\\nðŸ”¥ Training epochs {start_epoch} â†’ {EPOCHS}')\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs, labels)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f'{loss.item():.4f}')\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_path = f'{CKPT_DIR}/epoch_{epoch+1}.pth'\n",
    "    torch.save({'epoch': epoch, 'model': model.state_dict(), 'optim': optimizer.state_dict()}, save_path)\n",
    "    print(f'ðŸ’¾ Epoch {epoch+1} saved. Avg loss: {total_loss/len(loader):.4f}')\n",
    "\n",
    "print('\\nâœ… TRAINING COMPLETE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Export Final Model\n",
    "final_path = '/kaggle/working/prosopo_final.pth'\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(f'âœ… Final model saved to {final_path}')\n",
    "print('ðŸ“¥ Download from the \"Output\" tab on the right â†’')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
